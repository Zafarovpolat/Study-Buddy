# backend/app/services/vector_service.py
import google.generativeai as genai
from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import asyncio
from concurrent.futures import ThreadPoolExecutor
from uuid import UUID

from app.core.config import settings

_executor = ThreadPoolExecutor(max_workers=2)

# –†–∞–∑–º–µ—Ä chunk –≤ —Å–∏–º–≤–æ–ª–∞—Ö
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100


class VectorService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è vector search (RAG)"""
    
    def __init__(self, db: AsyncSession):
        self.db = db
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
    
    def _split_into_chunks(self, text: str) -> List[Dict[str, Any]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ chunks —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
        chunks = []
        start = 0
        chunk_index = 0
        
        while start < len(text):
            end = start + CHUNK_SIZE
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é
            if end < len(text):
                # –ò—â–µ–º –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                for sep in ['. ', '.\n', '! ', '? ', '\n\n']:
                    last_sep = text[start:end].rfind(sep)
                    if last_sep > CHUNK_SIZE // 2:
                        end = start + last_sep + len(sep)
                        break
            
            chunk_text = text[start:end].strip()
            
            if chunk_text:
                chunks.append({
                    "content": chunk_text,
                    "chunk_index": chunk_index,
                    "char_start": start,
                    "char_end": end
                })
                chunk_index += 1
            
            start = end - CHUNK_OVERLAP
            if start < 0:
                start = end
        
        return chunks
    
    def _get_embedding_sync(self, text: str) -> List[float]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ embedding"""
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    
    async def _get_embedding(self, text: str) -> List[float]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ embedding"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(_executor, self._get_embedding_sync, text)
    
    async def index_material(self, material_id: UUID, user_id: UUID, content: str) -> int:
        """–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª ‚Äî —Å–æ–∑–¥–∞—ë—Ç chunks —Å embeddings"""
        if not content or len(content.strip()) < 50:
            return 0
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ chunks
        await self.db.execute(
            text("DELETE FROM text_chunks WHERE material_id = :material_id"),
            {"material_id": str(material_id)}
        )
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ chunks
        chunks = self._split_into_chunks(content)
        
        print(f"üìä Indexing {len(chunks)} chunks for material {material_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º embeddings –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        for chunk in chunks:
            try:
                embedding = await self._get_embedding(chunk["content"])
                
                await self.db.execute(
                    text("""
                        INSERT INTO text_chunks (material_id, user_id, content, chunk_index, embedding)
                        VALUES (:material_id, :user_id, :content, :chunk_index, :embedding)
                    """),
                    {
                        "material_id": str(material_id),
                        "user_id": str(user_id),
                        "content": chunk["content"],
                        "chunk_index": chunk["chunk_index"],
                        "embedding": embedding
                    }
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to index chunk {chunk['chunk_index']}: {e}")
        
        await self.db.commit()
        print(f"‚úÖ Indexed {len(chunks)} chunks")
        
        return len(chunks)
    
    async def search(
        self, 
        user_id: UUID, 
        query: str, 
        limit: int = 5,
        material_id: Optional[UUID] = None
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–∞–º"""
        # –ü–æ–ª—É—á–∞–µ–º embedding –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = await self._get_embedding(query)
        
        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö chunks
        if material_id:
            # –ü–æ–∏—Å–∫ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –º–∞—Ç–µ—Ä–∏–∞–ª–µ
            result = await self.db.execute(
                text("""
                    SELECT 
                        tc.id,
                        tc.material_id,
                        tc.content,
                        tc.chunk_index,
                        m.title as material_title,
                        1 - (tc.embedding <=> :embedding) as similarity
                    FROM text_chunks tc
                    JOIN materials m ON m.id = tc.material_id
                    WHERE tc.material_id = :material_id
                    ORDER BY tc.embedding <=> :embedding
                    LIMIT :limit
                """),
                {
                    "embedding": query_embedding,
                    "material_id": str(material_id),
                    "limit": limit
                }
            )
        else:
            # –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            result = await self.db.execute(
                text("""
                    SELECT 
                        tc.id,
                        tc.material_id,
                        tc.content,
                        tc.chunk_index,
                        m.title as material_title,
                        1 - (tc.embedding <=> :embedding) as similarity
                    FROM text_chunks tc
                    JOIN materials m ON m.id = tc.material_id
                    WHERE tc.user_id = :user_id
                    ORDER BY tc.embedding <=> :embedding
                    LIMIT :limit
                """),
                {
                    "embedding": query_embedding,
                    "user_id": str(user_id),
                    "limit": limit
                }
            )
        
        rows = result.fetchall()
        
        return [
            {
                "id": str(row.id),
                "material_id": str(row.material_id),
                "material_title": row.material_title,
                "content": row.content,
                "chunk_index": row.chunk_index,
                "similarity": float(row.similarity)
            }
            for row in rows
        ]
    
    async def ask_library(self, user_id: UUID, question: str) -> Dict[str, Any]:
        """–°–ø—Ä–æ—Å–∏ —Å–≤–æ—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É ‚Äî RAG"""
        # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ chunks
        chunks = await self.search(user_id, question, limit=5)
        
        if not chunks:
            return {
                "answer": "–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
                "sources": []
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_parts = []
        for chunk in chunks:
            context_parts.append(
                f"[–ò–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–∞: {chunk['material_title']}]\n{chunk['content']}"
            )
        
        context = "\n\n---\n\n".join(context_parts)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        prompt = f"""–¢—ã ‚Äî —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —É—á—ë–±—ã. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, 
–∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –£–∫–∞–∑—ã–≤–∞–π –∏–∑ –∫–∞–∫–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
4. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω

–û—Ç–≤–µ—Ç:"""

        try:
            from app.services.ai_service import gemini_service
            answer = await gemini_service._generate_async(prompt)
            
            return {
                "answer": answer,
                "sources": [
                    {
                        "material_id": chunk["material_id"],
                        "material_title": chunk["material_title"],
                        "similarity": chunk["similarity"]
                    }
                    for chunk in chunks
                ]
            }
        except Exception as e:
            print(f"‚ùå RAG error: {e}")
            return {
                "answer": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                "sources": []
            }